import numpy as np

def calculate_metrics(confusion_matrix):
    num_classes = confusion_matrix.shape[0]
    metrics = {}

    for i in range(num_classes):
        tp = confusion_matrix[i, i]  # True positives
        fp = np.sum(confusion_matrix[:, i]) - tp  # False positives
        fn = np.sum(confusion_matrix[i, :]) - tp  # False negatives
        tn = np.sum(confusion_matrix) - (tp + fp + fn)  # True negatives

        recall = tp / (tp + fn)  # True positive rate (Sensitivity)
        precision = tp / (tp + fp)  # Positive predictive value
        f1_score = 2 * (precision * recall) / (precision + recall)  # Harmonic mean of precision and recall

        metrics[f"Class {i+1}"] = {
            "Recall": recall,
            "Precision": precision,
            "F1-Score": f1_score
        }

    # Calculate balanced accuracy
    tp = np.diag(confusion_matrix)  # True positives
    fn = np.sum(confusion_matrix, axis=1) - tp  # False negatives
    balanced_accuracy = np.mean(tp / (tp + fn))
    metrics["Balanced Accuracy"] = balanced_accuracy

    return metrics

# 예시 혼동 행렬 생성 (11개의 클래스를 가정)
confusion_matrix = np.array([[5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [1, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5]])

metrics = calculate_metrics(confusion_matrix)

# 결과 출력
for class_name, class_metrics in metrics.items():
    print(class_name + ":")
    print(f"Recall: {class_metrics['Recall']}")
    print(f"Precision: {class_metrics['Precision']}")
    print(f"F1-Score: {class_metrics['F1-Score']}")
    print()
