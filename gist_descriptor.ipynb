{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in ./opt/anaconda3/lib/python3.9/site-packages (0.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (2.8.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (1.21.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (2.19.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import view_as_blocks\n",
    "\n",
    "# Gabor 필터 생성 함수\n",
    "def create_filters(scales, orientations):\n",
    "    filters = []\n",
    "    for scale in range(scales[0], scales[1] + 1):\n",
    "        for orientation in np.arange(0, np.pi, np.pi / orientations):\n",
    "            filt_real = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0, ktype=cv2.CV_32F)\n",
    "            filt_imag = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0.5 * np.pi, ktype=cv2.CV_32F)\n",
    "            filt = filt_real + filt_imag\n",
    "            filt /= 2.0 * np.pi * scale * scale\n",
    "            filters.append(filt)\n",
    "    return filters\n",
    "\n",
    "# GIST 디스크립터 계산 함수\n",
    "def gist_descriptor_single_channel(image, scales=(8, 8), orientations=8, blocks=(4, 4)):    # Gabor 필터 생성\n",
    "    filters = create_filters(scales, orientations)\n",
    "    \n",
    "    # 이미지 크기와 블록 크기 계산\n",
    "    height, width = image.shape[:2]\n",
    "    block_size = height // blocks[0], width // blocks[1]\n",
    "\n",
    "    padding_size = blocks[0] * block_size[0] - height, blocks[1] * block_size[1] - width\n",
    "    \n",
    "    # 이미지 패딩 (필요한 경우)\n",
    "    if padding_size != (0, 0):\n",
    "        image = cv2.copyMakeBorder(image, 0, padding_size[0], 0, padding_size[1], cv2.BORDER_CONSTANT, value=0)\n",
    "    \n",
    "    # 이미지를 블록으로 분할\n",
    "    block_shape = (block_size[0], block_size[1])\n",
    "    blocks = view_as_blocks(image, block_shape=(block_size[0], block_size[1])).reshape(-1, *block_size, order='F')\n",
    "    \n",
    "    # 각 블록의 GIST 특성 추출\n",
    "    features = []\n",
    "    for block in blocks:\n",
    "        feats = []\n",
    "        for scale in filters:\n",
    "            for filt in scale:\n",
    "                filtered = cv2.filter2D(block, cv2.CV_64F, filt)\n",
    "                feats.append(filtered.mean())\n",
    "        features.append(feats)\n",
    "    \n",
    "    # 전체 GIST 디스크립터로 결합\n",
    "    return np.concatenate(features)\n",
    "\n",
    "\n",
    "def gist_descriptor(image, scales=(8, 8), orientations=8, blocks=(4, 4)):\n",
    "    if len(image.shape) == 3:\n",
    "    # 각 채널에 대해 GIST 디스크립터 계산\n",
    "        descriptors = [gist_descriptor_single_channel(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), scales, orientations, blocks)]            # 전체 GIST 디스크립터로 결합\n",
    "        return np.concatenate(descriptors)\n",
    "    else:\n",
    "    # 단일 채널 이미지의 경우 GIST 디스크립터를 한 번만 계산\n",
    "        return gist_descriptor_single_channel(image, scales, orientations, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/parkhyunjae/Downloads/malware/semi_train\n"
     ]
    }
   ],
   "source": [
    "cd /Users/parkhyunjae/Downloads/malware/semi_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 악성코드 이미지 폴더에서 350개의 이미지에 대한 gist descriptor를 계산하여 반환\n",
    "def get_gist_descriptors(root_dir):\n",
    "    descriptors = []\n",
    "    for subdir in sorted(os.listdir(root_dir)):\n",
    "        subdir_path = os.path.join(root_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            print(\"Processing directory:\", subdir_path)\n",
    "            for i, filename in enumerate(os.listdir(subdir_path)):\n",
    "                # 파일 경로 생성\n",
    "                filepath = os.path.join(subdir_path, filename)\n",
    "                # 이미지 로드\n",
    "                image = cv2.imread(filepath)\n",
    "                # 이미지에 대한 GIST 디스크립터 계산\n",
    "                descriptor = gist_descriptor(image)\n",
    "                descriptors.append(descriptor)\n",
    "                \n",
    "                if i % 10 == 9:\n",
    "                    print(\"\\tProcessed\", i + 1, \"images\")\n",
    "    return np.array(descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: semi_train/Adposhel\n",
      "\tProcessed 10 images\n",
      "Processing directory: semi_train/Agent\n",
      "Processing directory: semi_train/Dinwod\n",
      "Processing directory: semi_train/Elex\n",
      "Processing directory: semi_train/Vilsel\n",
      "\tProcessed 10 images\n",
      "43\n",
      "GIST Descriptor Shape: (43, 1152)\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"semi_train/\"\n",
    "# 각 폴더에서 350개의 이미지에 대한 gist descriptor 계산\n",
    "descriptors = get_gist_descriptors(root_dir)\n",
    "print(len(descriptors))\n",
    "print('GIST Descriptor Shape:', descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: xgboost in /Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "accuracy 0.8888888888888888\n",
      "FPR 0.02222222222222222\n",
      "precision 0.8888888888888888\n",
      "recall 0.8888888888888888\n",
      "f1score 0.8888888888888888\n",
      "XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7777777777777778\n",
      "FPR 0.04722222222222222\n",
      "precision 0.8888888888888888\n",
      "recall 0.7777777777777778\n",
      "f1score 0.8148148148148148\n",
      "Linear SVM\n",
      "accuracy 0.8888888888888888\n",
      "FPR 0.03571428571428571\n",
      "precision 0.8148148148148148\n",
      "recall 0.8888888888888888\n",
      "f1score 0.8444444444444444\n",
      "SMO\n",
      "accuracy 0.8888888888888888\n",
      "FPR 0.02222222222222222\n",
      "precision 0.8888888888888888\n",
      "recall 0.8888888888888888\n",
      "f1score 0.8888888888888888\n",
      "J48\n",
      "accuracy 0.7777777777777778\n",
      "FPR 0.07142857142857142\n",
      "precision 0.7037037037037037\n",
      "recall 0.7777777777777778\n",
      "f1score 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/parkhyunjae/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 데이터와 레이블 설정\n",
    "X = descriptors\n",
    "\n",
    "# 레이블 기록\n",
    "labels_dict = {\n",
    "    'Adposhel': 0,\n",
    "    'Agent': 1,\n",
    "    'Dinwod': 2,\n",
    "    'Elex': 3,\n",
    "    'Vilsel': 4\n",
    "}\n",
    "\n",
    "# 각 이미지에 맞는 레이블 생성\n",
    "y = []\n",
    "for subdir in sorted(os.listdir(root_dir)):\n",
    "    subdir_path = os.path.join(root_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for i, filename in enumerate(sorted(os.listdir(subdir_path))):\n",
    "            y.append(labels_dict[subdir])\n",
    "y = np.array(y)\n",
    "\n",
    "# train-test 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Linear SVM': LinearSVC(),\n",
    "    'SMO': SVC(kernel='rbf'), # SMO는 일반적으로 서포트 벡터 머신 (SVM)이 rbf 커널을 사용\n",
    "    'J48': DecisionTreeClassifier() # J48는 scikit-learn에서 Decision Tree에 해당\n",
    "}\n",
    "\n",
    "# 성능 지표\n",
    "scores = {'accuracy': accuracy_score, 'FPR': confusion_matrix, 'precision': precision_score, 'recall': recall_score, 'f1score': f1_score}\n",
    "\n",
    "# 각 모델에 대해 교차 검증 및 테스트 세트에서 성능 평가\n",
    "for model_name, model_instance in models.items():\n",
    "    print(model_name)\n",
    "    model_instance.fit(X_train_scaled, y_train)\n",
    "    y_pred = model_instance.predict(X_test_scaled)\n",
    "    for score_name, score_func in scores.items():\n",
    "        if score_name == 'FPR':\n",
    "            cm = score_func(y_test, y_pred)\n",
    "            fp = cm.sum(axis=0) - np.diag(cm)\n",
    "            tn = cm.sum() - (cm.sum(axis=1) + fp)\n",
    "            fpr = np.mean(fp / (fp + tn))\n",
    "            print(score_name, fpr)\n",
    "        elif score_name == 'accuracy':\n",
    "            print(score_name, score_func(y_test, y_pred))\n",
    "        else:\n",
    "            print(score_name, score_func(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcc0b0613e16cd07ff7dba9bb52fd60af7a74a31d4c76084d5063f45f28d096a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
