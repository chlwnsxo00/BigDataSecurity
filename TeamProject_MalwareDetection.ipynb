{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlwnsxo00/BigDataSecurity/blob/main/TeamProject_MalwareDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 드라이브 설정"
      ],
      "metadata": {
        "id": "Aale8Jxv8bhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM_o_ZM66OcU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/Shareddrives/BigDataSecurity'"
      ],
      "metadata": {
        "id": "YsYarYqG6S4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "HzfOCDO86Wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "LlbI6roy8goa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data\n",
        "import os\n",
        "import time\n"
      ],
      "metadata": {
        "id": "ckUwJYuE6Zep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True # prevent truncate error"
      ],
      "metadata": {
        "id": "3LEOq0sGlUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 불러오기\n"
      ],
      "metadata": {
        "id": "UMfcc6IX8l-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
        "\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ],
      "metadata": {
        "id": "lvCE5UbP8sMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),        \n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "yE3cKQrFlhK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageFolderWithPaths(root = './malware/' + \"train\", # load train data\n",
        "                                   transform = image_transforms['train'],\n",
        "                                  )\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True) # make train loader"
      ],
      "metadata": {
        "id": "SfHDr1YE8r4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = ImageFolderWithPaths(root = './malware/' + \"val\", # load test data\n",
        "                                   transform = image_transforms['test'],\n",
        "                                  )\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False) # make test loader"
      ],
      "metadata": {
        "id": "IbvHCg1jk2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "AIoHfAVrkwU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "ZlYi36NXlFEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_size = int(0.5 * len(test_data))\n",
        "# test_size = len(test_data) - val_size\n",
        "\n",
        "# valid_data, test_data = torch.utils.data.random_split(test_data, [val_size, test_size])"
      ],
      "metadata": {
        "id": "jTdomjCNlpbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.class_to_idx # class name\n",
        "classes"
      ],
      "metadata": {
        "id": "jW1vepJ_mGQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "# print(dataiter.next())\n",
        "images, labels, paths = next(dataiter)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print()\n",
        "labels = labels.tolist()\n",
        "print(' '.join(f'{list(classes.keys())[list(classes.values()).index(j)]}' for j in labels))"
      ],
      "metadata": {
        "id": "A5r9_7v1mCHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA 및 전처리"
      ],
      "metadata": {
        "id": "9kIZ0uDE8sfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T-SNE"
      ],
      "metadata": {
        "id": "V4SVucEQE6Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VnLcPKnjFHDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE를 수행할 데이터 로드\n",
        "dataiter = iter(train_loader)  # train_loader는 데이터를 로드하는 DataLoader 객체입니다.\n",
        "images, labels, paths = next(dataiter)"
      ],
      "metadata": {
        "id": "aYevis7pFJP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Todo\n",
        "# 데이터 전처리\n",
        "# 필요한 전처리 작업을 수행합니다.\n",
        "# 예시: 데이터에서 특정 열 추출\n",
        "\n",
        "X = images.view(images.size(0), -1).numpy()"
      ],
      "metadata": {
        "id": "sd-sDLnUFKiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 모델 생성 및 학습\n",
        "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
        "tsne_result = tsne.fit_transform(X)"
      ],
      "metadata": {
        "id": "owiIiM85FSqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 결과를 시각화\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='viridis')\n",
        "plt.title('T-SNE Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kpATI3tVFUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GIST"
      ],
      "metadata": {
        "id": "E_Dqm17NFFTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-gist"
      ],
      "metadata": {
        "id": "g9fAU5z4qpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gists.py"
      ],
      "metadata": {
        "id": "qr4x57TSr8tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gist"
      ],
      "metadata": {
        "id": "K6l1xtUD8ysZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성"
      ],
      "metadata": {
        "id": "XMOtVX1T8zu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "e0yB7kJWG9oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 준비\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for images, labels, paths in train_loader:\n",
        "    # 이미지 데이터를 1차원 벡터로 변환\n",
        "    images = images.view(images.size(0), -1)\n",
        "    train_images.append(images.numpy())\n",
        "    train_labels.append(labels.numpy())\n",
        "\n",
        "train_images = np.concatenate(train_images, axis=0)\n",
        "train_labels = np.concatenate(train_labels, axis=0)\n",
        "\n",
        "# 테스트 데이터 준비\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for images, labels, paths in test_loader:\n",
        "    # 이미지 데이터를 1차원 벡터로 변환\n",
        "    images = images.view(images.size(0), -1)\n",
        "    test_images.append(images.numpy())\n",
        "    test_labels.append(labels.numpy())\n",
        "\n",
        "test_images = np.concatenate(test_images, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "# Random Forest 모델 생성 및 학습\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(train_images, train_labels)\n",
        "\n",
        "# 예측\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "127llhZJ86o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "xBZt7eFTG_eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        ############### Conv2d, MaxPool2d, Linear 함수에 들어갈 파라미터를 채우세요 ##############\n",
        "        self.conv1 = nn.Conv2d(3, 5, 3) # in_channel, out_channel, kernel size\n",
        "        self.pool = nn.MaxPool2d(3, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "        self.fc1 = nn.Linear(58320, 160) # in_features, out_features\n",
        "        self.fc2 = nn.Linear(160, 120)\n",
        "        self.fc3 = nn.Linear(120, 26)\n",
        "        ###########################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "v4O6A1FR9B1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use GPU if it's available # colab 런타임 유형 변경에서 GPU 선택할 것"
      ],
      "metadata": {
        "id": "XAoj_dDUtE4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net() # define the network\n",
        "model = model.to(device) # send the network to the device"
      ],
      "metadata": {
        "id": "z1PQXIs_tF6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() # loss function, 변경 가능\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001) # optimizer, 변경 가능\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "_Znw7sqgtHUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(k, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        corrects = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct = corrects[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc = correct/ batch_size\n",
        "    return acc"
      ],
      "metadata": {
        "id": "PRTWnM01tP6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, x in enumerate(train_loader):\n",
        "  print(x[0])\n",
        "  print(x[1])\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "AoFYMktXxcLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for idx, data in enumerate(iterator):\n",
        "        \n",
        "        x = data[0].to(device)\n",
        "        y = data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_topk_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "zzcu9Jc3tQla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for idx, data in enumerate(iterator):\n",
        "\n",
        "           x = data[0].to(device)\n",
        "           y = data[1].to(device)\n",
        "\n",
        "           y_pred = model(x)\n",
        "\n",
        "           loss = criterion(y_pred, y)\n",
        "\n",
        "           acc = calculate_topk_accuracy(y_pred, y)\n",
        "\n",
        "           epoch_loss += loss.item()\n",
        "           epoch_acc += acc.item()\n",
        "\n",
        "          \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "Po3cidDMtRtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "uOy4XC3gtToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "NA_DlGantW-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, test_loader, criterion, device)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:6.2f}%')"
      ],
      "metadata": {
        "id": "8QPsTuWKtUbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "LmhpfKR387Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vt_ASe_q87JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qO-WJvKE9Aqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "18G7yplz89Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7jmDtKO9Aam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBcW3D2388_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}