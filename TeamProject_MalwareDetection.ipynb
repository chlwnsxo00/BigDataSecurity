{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckj18/BigDataSecurity/blob/main/TeamProject_MalwareDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 드라이브 설정"
      ],
      "metadata": {
        "id": "Aale8Jxv8bhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM_o_ZM66OcU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/Shareddrives/BigDataSecurity'"
      ],
      "metadata": {
        "id": "YsYarYqG6S4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "HzfOCDO86Wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "LlbI6roy8goa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import torch.utils.data\n",
        "import os\n",
        "import time\n",
        "# 전처리\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog"
      ],
      "metadata": {
        "id": "ckUwJYuE6Zep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True # prevent truncate error"
      ],
      "metadata": {
        "id": "3LEOq0sGlUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 불러오기\n"
      ],
      "metadata": {
        "id": "UMfcc6IX8l-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),        \n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "yE3cKQrFlhK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root = './malware/train', \n",
        "                                  transform = image_transforms['train'])\n",
        "\n",
        "test_data = datasets.ImageFolder(root = './malware/val', \n",
        "                                 transform = image_transforms['test'])"
      ],
      "metadata": {
        "id": "SfHDr1YE8r4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = int(4 * len(test_data) / 11)\n",
        "add_size = int(3 * len(test_data) / 11)\n",
        "test_size = int(4 * len(test_data) / 11)\n",
        "\n",
        "valid_data, test_data, add_data = torch.utils.data.random_split(test_data, [val_size, test_size, add_size])\n",
        "train_data = torch.utils.data.ConcatDataset([train_data, add_data])"
      ],
      "metadata": {
        "id": "IbvHCg1jk2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True) # make train loader\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=128, shuffle=False) # make test loader\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False) # make test loader"
      ],
      "metadata": {
        "id": "jW1vepJ_mGQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "id": "cS7alUIxwkKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "# print(dataiter.next())\n",
        "images, labels, paths = next(dataiter)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print()\n",
        "labels = labels.tolist()\n",
        "print(' '.join(f'{list(classes.keys())[list(classes.values()).index(j)]}' for j in labels))"
      ],
      "metadata": {
        "id": "A5r9_7v1mCHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA 및 전처리"
      ],
      "metadata": {
        "id": "9kIZ0uDE8sfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 수행을 위한 데이터 로드\n",
        "batch_size = 32  # 배치 크기 설정\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "num_batches = len(train_loader)  # 배치의 개수\n",
        "\n",
        "images = []\n",
        "CLAHE_images = []\n",
        "WT_images = []\n",
        "\n",
        "for _ in range(num_batches):\n",
        "    batch_images, labels, paths = next(dataiter)\n",
        "\n",
        "    batch_images_processed = []\n",
        "    batch_CLAHE_images = []\n",
        "    batch_WT_images = []\n",
        "\n",
        "    for path in paths:\n",
        "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # CLAHE \n",
        "        clahe = cv2.createCLAHE(clipLimit=0.02, tileGridSize=(4,4))\n",
        "        CLAHE_image = clahe.apply(image)\n",
        "\n",
        "        # Wavelet transform\n",
        "        wavelet = 'db5'  # Daubechies family\n",
        "        level = 2  # Number of decomposition levels\n",
        "        coeffs = pywt.wavedec2(CLAHE_image, wavelet, level=level)\n",
        "\n",
        "        # 재구성\n",
        "        WT_image = pywt.waverec2(coeffs, wavelet)\n",
        "\n",
        "        batch_images_processed.append(image)\n",
        "        batch_CLAHE_images.append(CLAHE_image)\n",
        "        batch_WT_images.append(WT_image)\n",
        "\n",
        "    images.append(batch_images_processed)\n",
        "    CLAHE_images.append(batch_CLAHE_images)\n",
        "    WT_images.append(batch_WT_images)\n",
        "\n",
        "images = np.array(images)\n",
        "CLAHE_images = np.array(CLAHE_images)\n",
        "WT_images = np.array(WT_images)"
      ],
      "metadata": {
        "id": "8Pq-t1ANXx3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contrast 조정 ( CLAHE ) 시각화"
      ],
      "metadata": {
        "id": "wXmJeqU6WZTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv2.imread(path,0);\n",
        "\n",
        "# contrast limit가 0.02이고 title의 size는 4X4\n",
        "clahe = cv2.createCLAHE(clipLimit=0.02, tileGridSize=(4,4))\n",
        "img2 = clahe.apply(img)\n",
        "\n",
        "# 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title('Before')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(img2, cmap='gray')\n",
        "axes[1].set_title('After')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6eduL8i1W4C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  영상 압축( Wavelet Transform ) 시각화"
      ],
      "metadata": {
        "id": "itn7qnyHWmYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이미지 로드\n",
        "image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Wavelet transform\n",
        "wavelet = 'db5'  # Daubechies family\n",
        "level = 2  # Number of decomposition levels\n",
        "coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
        "\n",
        "# 재구성\n",
        "reconstructed_image = pywt.waverec2(coeffs, wavelet)\n",
        "\n",
        "# 원본 이미지와 재구성 이미지 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(image, cmap='gray')\n",
        "axes[0].set_title('Original Image')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(reconstructed_image, cmap='gray')\n",
        "axes[1].set_title('Reconstructed Image')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y_TreQjCWshX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOG"
      ],
      "metadata": {
        "id": "FWmDitISpg_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hog = cv2.HOGDescriptor()\n",
        "\n",
        "hog_features = []\n",
        "\n",
        "for batch_images in WT_images:\n",
        "    batch_hog_features = []\n",
        "    \n",
        "    for image in batch_images:\n",
        "        hog_feature = hog.compute(image)  # Compute HOG features\n",
        "        batch_hog_features.append(hog_feature.flatten())\n",
        "    \n",
        "    batch_hog_features = np.array(batch_hog_features)\n",
        "    hog_features.append(batch_hog_features)\n",
        "\n",
        "hog_features = np.array(hog_features)"
      ],
      "metadata": {
        "id": "T-FYWPkUp19r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GIST"
      ],
      "metadata": {
        "id": "E_Dqm17NFFTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-gist"
      ],
      "metadata": {
        "id": "g9fAU5z4qpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gists.py"
      ],
      "metadata": {
        "id": "qr4x57TSr8tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gist"
      ],
      "metadata": {
        "id": "K6l1xtUD8ysZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SIFT"
      ],
      "metadata": {
        "id": "LPbFf12KjLrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "XhBt_ckGjPFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIFT 시각화\n",
        "img = cv2.imread(path)\n",
        "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sift = cv2.SIFT_create()\n",
        "kp = sift.detect(gray,None)\n",
        "\n",
        "img=cv2.drawKeypoints(gray,kp, img)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.title('SIFT')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KePVtWswjXtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors = []\n",
        "\n",
        "for image in enhanced_images:\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints, descriptor = sift.detectAndCompute(image, None)\n",
        "    \n",
        "    # Store the descriptors\n",
        "    descriptors.append(descriptor)"
      ],
      "metadata": {
        "id": "b84XZeC1oIkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T-SNE"
      ],
      "metadata": {
        "id": "V4SVucEQE6Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VnLcPKnjFHDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 정보 가져오기\n",
        "class_labels = [list(classes.keys())[list(classes.values()).index(i)] for i in labels]\n",
        "\n",
        "# 클래스별 색상 매핑\n",
        "class_colors = ['red', 'blue', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink',\n",
        "                'lightblue', 'brown', 'gray', 'olive', 'teal', 'navy', 'salmon', 'gold', 'lightgreen', 'lavender',\n",
        "                'skyblue', 'tan', 'coral', 'orchid', 'darkgreen', 'silver']"
      ],
      "metadata": {
        "id": "Dtm2FgJlriKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 모델 생성 및 학습 (SIFT로 추출한 feature 사용)\n",
        "# Concatenate the descriptors for each image\n",
        "all_descriptors = np.concatenate([d for d in descriptors if d is not None], axis=0)\n",
        "\n",
        "# Apply T-SNE to reduce the dimensionality of the feature matrix\n",
        "tsne = TSNE(n_components=2, perplexity=10, learning_rate=200, random_state=42)\n",
        "embedded_features = tsne.fit_transform(all_descriptors)"
      ],
      "metadata": {
        "id": "y2h7FyZto-3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 결과를 시각화 ( SIFT 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(embedded_features[indices, 0], embedded_features[indices, 1], label=label, color=color)\n",
        "plt.title('T-SNE Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yQWemg5TIGJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 모델 생성 및 학습 ( HOG로 추출한 feature 사용)\n",
        "tsne = TSNE(n_components=2, perplexity=20, learning_rate=200, random_state=42)\n",
        "tsne_result = tsne.fit_transform(hog_features)"
      ],
      "metadata": {
        "id": "owiIiM85FSqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 결과를 시각화 (HOG 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=label, color=color)\n",
        "plt.title('T-SNE Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kpATI3tVFUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UMAP"
      ],
      "metadata": {
        "id": "xtfhskOyifzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "roIOE1wrjC86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NdaOk-5fihMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 정보 가져오기\n",
        "class_labels = [list(classes.keys())[list(classes.values()).index(i)] for i in labels]\n",
        "\n",
        "# 클래스별 색상 매핑\n",
        "class_colors = ['red', 'blue', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink',\n",
        "                'lightblue', 'brown', 'gray', 'olive', 'teal', 'navy', 'salmon', 'gold', 'lightgreen', 'lavender',\n",
        "                'skyblue', 'tan', 'coral', 'orchid', 'darkgreen', 'silver']"
      ],
      "metadata": {
        "id": "bWEfXTfcj2Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 모델 생성 및 학습 ( SIFT로 추출한 feature 사용)\n",
        "umap_model = umap.UMAP(n_components=2, learning_rate=200, random_state=42)\n",
        "umap_result = umap_model.fit_transform(embedded_features)"
      ],
      "metadata": {
        "id": "RBTriDwRJrMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 결과를 시각화 ( SIFT로 추출한 feature 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(umap_result[indices, 0], umap_result[indices, 1], label=label, color=color)\n",
        "plt.title('UMAP Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ref4iSBEJrrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 모델 생성 및 학습 ( HOG로 추출한 feature 사용)\n",
        "umap_model = umap.UMAP(n_components=2, learning_rate=200, random_state=42)\n",
        "umap_result = umap_model.fit_transform(hog_features)"
      ],
      "metadata": {
        "id": "5H6ONC1MijtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 결과를 시각화 ( HOG로 추출한 feature 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(umap_result[indices, 0], umap_result[indices, 1], label=label, color=color)\n",
        "plt.title('UMAP Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sd4DWeSTiqyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성"
      ],
      "metadata": {
        "id": "XMOtVX1T8zu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "e0yB7kJWG9oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 준비\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for images, labels, paths in train_loader:\n",
        "    # 이미지 데이터를 1차원 벡터로 변환\n",
        "    images = images.view(images.size(0), -1)\n",
        "    train_images.append(images.numpy())\n",
        "    train_labels.append(labels.numpy())\n",
        "\n",
        "train_images = np.concatenate(train_images, axis=0)\n",
        "train_labels = np.concatenate(train_labels, axis=0)\n",
        "\n",
        "# 테스트 데이터 준비\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for images, labels, paths in test_loader:\n",
        "    # 이미지 데이터를 1차원 벡터로 변환\n",
        "    images = images.view(images.size(0), -1)\n",
        "    test_images.append(images.numpy())\n",
        "    test_labels.append(labels.numpy())\n",
        "\n",
        "test_images = np.concatenate(test_images, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "# Random Forest 모델 생성 및 학습\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(train_images, train_labels)\n",
        "\n",
        "# 예측\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "127llhZJ86o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "xBZt7eFTG_eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        ############### Conv2d, MaxPool2d, Linear 함수에 들어갈 파라미터를 채우세요 ##############\n",
        "        self.conv1 = nn.Conv2d(3, 5, 3) # in_channel, out_channel, kernel size\n",
        "        self.pool = nn.MaxPool2d(3, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "        self.fc1 = nn.Linear(58320, 160) # in_features, out_features\n",
        "        self.fc2 = nn.Linear(160, 120)\n",
        "        self.fc3 = nn.Linear(120, 26)\n",
        "        ###########################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "v4O6A1FR9B1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use GPU if it's available # colab 런타임 유형 변경에서 GPU 선택할 것"
      ],
      "metadata": {
        "id": "XAoj_dDUtE4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net() # define the network\n",
        "model = model.to(device) # send the network to the device"
      ],
      "metadata": {
        "id": "z1PQXIs_tF6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() # loss function, 변경 가능\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001) # optimizer, 변경 가능\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "_Znw7sqgtHUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(k, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        corrects = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct = corrects[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc = correct/ batch_size\n",
        "    return acc"
      ],
      "metadata": {
        "id": "PRTWnM01tP6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, x in enumerate(train_loader):\n",
        "  print(x[0])\n",
        "  print(x[1])\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "AoFYMktXxcLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for idx, data in enumerate(iterator):\n",
        "        \n",
        "        x = data[0].to(device)\n",
        "        y = data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_topk_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "zzcu9Jc3tQla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for idx, data in enumerate(iterator):\n",
        "\n",
        "           x = data[0].to(device)\n",
        "           y = data[1].to(device)\n",
        "\n",
        "           y_pred = model(x)\n",
        "\n",
        "           loss = criterion(y_pred, y)\n",
        "\n",
        "           acc = calculate_topk_accuracy(y_pred, y)\n",
        "\n",
        "           epoch_loss += loss.item()\n",
        "           epoch_acc += acc.item()\n",
        "\n",
        "          \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "Po3cidDMtRtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "uOy4XC3gtToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "NA_DlGantW-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, test_loader, criterion, device)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:6.2f}%')"
      ],
      "metadata": {
        "id": "8QPsTuWKtUbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "LmhpfKR387Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vt_ASe_q87JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qO-WJvKE9Aqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "18G7yplz89Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7jmDtKO9Aam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBcW3D2388_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}