{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckj18/BigDataSecurity/blob/main/TeamProject_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 드라이브 설정"
      ],
      "metadata": {
        "id": "Aale8Jxv8bhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM_o_ZM66OcU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/Shareddrives/BigDataSecurity'"
      ],
      "metadata": {
        "id": "YsYarYqG6S4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "HzfOCDO86Wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "LlbI6roy8goa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import torch.utils.data\n",
        "import os\n",
        "import time\n",
        "# 전처리\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog"
      ],
      "metadata": {
        "id": "ckUwJYuE6Zep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True # prevent truncate error"
      ],
      "metadata": {
        "id": "3LEOq0sGlUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 불러오기\n"
      ],
      "metadata": {
        "id": "UMfcc6IX8l-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),        \n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "yE3cKQrFlhK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malware_list = {'Adposhel': 1,\n",
        " 'Allaple': 2,\n",
        " 'Amonetize': 3,\n",
        " 'Autorun': 4,\n",
        " 'Other': 0,\n",
        " 'BrowseFox': 5,\n",
        " 'Dinwod': 6,\n",
        " 'InstallCore': 7,\n",
        " 'MultiPlug': 8,\n",
        " 'VBA': 9,\n",
        " 'Vilsel': 10}"
      ],
      "metadata": {
        "id": "wlneD9fy4ivH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, malware_list, transform=None):\n",
        "        self.root = root\n",
        "        self.malware_list = malware_list\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        self.folder_to_label = {}  # 폴더명과 클래스 레이블 매핑을 위한 딕셔너리\n",
        "        self.class_counts = {}  # 클래스별 이미지 개수를 저장하는 딕셔너리\n",
        "\n",
        "        for idx, folder_name in enumerate(os.listdir(root)):\n",
        "            if folder_name in malware_list:\n",
        "                folder_path = os.path.join(root, folder_name)\n",
        "                self.folder_to_label[folder_name] = self.label_transform(folder_name)  # 폴더명에 대한 레이블 변환 결과 저장\n",
        "\n",
        "                count = 0  # 클래스별 이미지 개수 초기화\n",
        "                for image_name in os.listdir(folder_path):\n",
        "                    if image_name.endswith('.png'):  # 이미지 파일 확장자 지정\n",
        "                        image_path = os.path.join(folder_path, image_name)\n",
        "                        self.data.append(image_path)\n",
        "                        self.targets.append(folder_name)\n",
        "                        count += 1  # 클래스별 이미지 개수 증가\n",
        "\n",
        "                self.class_counts[folder_name] = count\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.data[index]\n",
        "        target = self.targets[index]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        target = self.folder_to_label[target]  # 폴더명에 대한 레이블 변환 결과 가져오기\n",
        "        return image, target, image_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def label_transform(self, label):\n",
        "        # 예시: 폴더명을 기준으로 클래스 레이블 변환\n",
        "        if label in malware_list:\n",
        "            return malware_list[label]\n",
        "\n",
        "def concat_datasets(datasets):\n",
        "    return ConcatDataset(datasets)\n"
      ],
      "metadata": {
        "id": "3YJ5LNDbq2fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path1 = './malware/train'\n",
        "test_path1 = './malware/val'"
      ],
      "metadata": {
        "id": "3H9fRwmkrBVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CustomDataset(root = train_path1, malware_list=malware_list,\n",
        "                                  transform = image_transforms['train'])\n",
        "test_data = CustomDataset(root = test_path1, malware_list=malware_list,\n",
        "                                  transform = image_transforms['test'])"
      ],
      "metadata": {
        "id": "SfHDr1YE8r4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset rebalance \n",
        "test_data, add_data = torch.utils.data.random_split(test_data, [1354, len(test_data) - 1354])\n",
        "\n",
        "train_data = ConcatDataset([train_data, test_data])"
      ],
      "metadata": {
        "id": "IbvHCg1jk2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "_balm98DrLNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TestLoader(Dataset):\n",
        "  val_size = int(0.5 * len(Dataset))\n",
        "  test_size = int(0.5 * len(Dataset))\n",
        "\n",
        "  valid_data, test_data = torch.utils.data.random_split(Dataset, [val_size, test_size])\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=128, shuffle=False) # make test loader\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False) # make test loader\n",
        "\n",
        "  return valid_loader, test_loader"
      ],
      "metadata": {
        "id": "hlF7Zr3JrMOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True) # make train loader\n",
        "valid_loader, test_loader = TestLoader(test_data) # make valid & test loader"
      ],
      "metadata": {
        "id": "jW1vepJ_mGQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_datasize():\n",
        "  print(f'Number of training examples: {len(train_data)}')\n",
        "  print(f'Number of validation examples: {int(len(test_data) / 2)}')\n",
        "  print(f'Number of testing examples: {int(len(test_data) / 2)}')\n",
        "\n",
        "show_datasize()"
      ],
      "metadata": {
        "id": "cS7alUIxwkKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_to_idx  = malware_list # class name"
      ],
      "metadata": {
        "id": "mRfacWXn5Jbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.class_to_idx\n",
        "classes"
      ],
      "metadata": {
        "id": "_H9c_LG_6WKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "# print(dataiter.next())\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print()\n",
        "\n",
        "labels = labels.tolist()\n",
        "print(' '.join(f'{list(classes.keys())[list(classes.values()).index(j)]}' for j in labels))"
      ],
      "metadata": {
        "id": "A5r9_7v1mCHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA 및 전처리"
      ],
      "metadata": {
        "id": "9kIZ0uDE8sfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 수행을 위한 데이터 로드\n",
        "batch_size = 32  # 배치 크기 설정\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "num_batches = len(train_loader)  # 배치의 개수\n",
        "\n",
        "images = []\n",
        "CLAHE_images = []\n",
        "WT_images = []\n",
        "\n",
        "for _ in range(num_batches):\n",
        "    batch_images, labels, paths = next(dataiter)\n",
        "\n",
        "    batch_images_processed = []\n",
        "    batch_CLAHE_images = []\n",
        "    batch_WT_images = []\n",
        "\n",
        "    for path in paths:\n",
        "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # CLAHE \n",
        "        clahe = cv2.createCLAHE(clipLimit=0.02, tileGridSize=(4,4))\n",
        "        CLAHE_image = clahe.apply(image)\n",
        "\n",
        "        # Wavelet transform\n",
        "        wavelet = 'db5'  # Daubechies family\n",
        "        level = 2  # Number of decomposition levels\n",
        "        coeffs = pywt.wavedec2(CLAHE_image, wavelet, level=level)\n",
        "\n",
        "        # 재구성\n",
        "        WT_image = pywt.waverec2(coeffs, wavelet)\n",
        "\n",
        "        batch_images_processed.append(image)\n",
        "        batch_CLAHE_images.append(CLAHE_image)\n",
        "        batch_WT_images.append(WT_image)\n",
        "\n",
        "    images.append(batch_images_processed)\n",
        "    CLAHE_images.append(batch_CLAHE_images)\n",
        "    WT_images.append(batch_WT_images)\n",
        "\n",
        "images = np.array(images)\n",
        "CLAHE_images = np.array(CLAHE_images)\n",
        "WT_images = np.array(WT_images)"
      ],
      "metadata": {
        "id": "8Pq-t1ANXx3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contrast 조정 ( CLAHE ) 시각화"
      ],
      "metadata": {
        "id": "wXmJeqU6WZTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv2.imread(path,0);\n",
        "\n",
        "# contrast limit가 0.02이고 title의 size는 4X4\n",
        "clahe = cv2.createCLAHE(clipLimit=0.02, tileGridSize=(4,4))\n",
        "img2 = clahe.apply(img)\n",
        "\n",
        "# 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title('Before')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(img2, cmap='gray')\n",
        "axes[1].set_title('After')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6eduL8i1W4C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  영상 압축( Wavelet Transform ) 시각화"
      ],
      "metadata": {
        "id": "itn7qnyHWmYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이미지 로드\n",
        "image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Wavelet transform\n",
        "wavelet = 'db5'  # Daubechies family\n",
        "level = 2  # Number of decomposition levels\n",
        "coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
        "\n",
        "# 재구성\n",
        "reconstructed_image = pywt.waverec2(coeffs, wavelet)\n",
        "\n",
        "# 원본 이미지와 재구성 이미지 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(image, cmap='gray')\n",
        "axes[0].set_title('Original Image')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(reconstructed_image, cmap='gray')\n",
        "axes[1].set_title('Reconstructed Image')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y_TreQjCWshX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOG"
      ],
      "metadata": {
        "id": "FWmDitISpg_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hog = cv2.HOGDescriptor()\n",
        "\n",
        "hog_features = []\n",
        "\n",
        "for batch_images in WT_images:\n",
        "    batch_hog_features = []\n",
        "    \n",
        "    for image in batch_images:\n",
        "        hog_feature = hog.compute(image)  # Compute HOG features\n",
        "        batch_hog_features.append(hog_feature.flatten())\n",
        "    \n",
        "    batch_hog_features = np.array(batch_hog_features)\n",
        "    hog_features.append(batch_hog_features)\n",
        "\n",
        "hog_features = np.array(hog_features)"
      ],
      "metadata": {
        "id": "T-FYWPkUp19r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GIST"
      ],
      "metadata": {
        "id": "E_Dqm17NFFTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-gist"
      ],
      "metadata": {
        "id": "g9fAU5z4qpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gists.py"
      ],
      "metadata": {
        "id": "qr4x57TSr8tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gist"
      ],
      "metadata": {
        "id": "K6l1xtUD8ysZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SIFT"
      ],
      "metadata": {
        "id": "LPbFf12KjLrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "XhBt_ckGjPFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIFT 시각화\n",
        "img = cv2.imread(path)\n",
        "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sift = cv2.SIFT_create()\n",
        "kp = sift.detect(gray,None)\n",
        "\n",
        "img=cv2.drawKeypoints(gray,kp, img)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.title('SIFT')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KePVtWswjXtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors = []\n",
        "\n",
        "for image in enhanced_images:\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints, descriptor = sift.detectAndCompute(image, None)\n",
        "    \n",
        "    # Store the descriptors\n",
        "    descriptors.append(descriptor)"
      ],
      "metadata": {
        "id": "b84XZeC1oIkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T-SNE"
      ],
      "metadata": {
        "id": "V4SVucEQE6Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VnLcPKnjFHDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 정보 가져오기\n",
        "class_labels = [list(classes.keys())[list(classes.values()).index(i)] for i in labels]\n",
        "\n",
        "# 클래스별 색상 매핑\n",
        "class_colors = ['red', 'blue', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink',\n",
        "                'lightblue', 'brown', 'gray', 'olive', 'teal', 'navy', 'salmon', 'gold', 'lightgreen', 'lavender',\n",
        "                'skyblue', 'tan', 'coral', 'orchid', 'darkgreen', 'silver']"
      ],
      "metadata": {
        "id": "Dtm2FgJlriKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 모델 생성 및 학습 (SIFT로 추출한 feature 사용)\n",
        "# Concatenate the descriptors for each image\n",
        "all_descriptors = np.concatenate([d for d in descriptors if d is not None], axis=0)\n",
        "\n",
        "# Apply T-SNE to reduce the dimensionality of the feature matrix\n",
        "tsne = TSNE(n_components=2, perplexity=10, learning_rate=200, random_state=42)\n",
        "embedded_features = tsne.fit_transform(all_descriptors)"
      ],
      "metadata": {
        "id": "y2h7FyZto-3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 결과를 시각화 ( SIFT 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(embedded_features[indices, 0], embedded_features[indices, 1], label=label, color=color)\n",
        "plt.title('T-SNE Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yQWemg5TIGJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 모델 생성 및 학습 ( HOG로 추출한 feature 사용)\n",
        "tsne = TSNE(n_components=2, perplexity=20, learning_rate=200, random_state=42)\n",
        "tsne_result = tsne.fit_transform(hog_features)"
      ],
      "metadata": {
        "id": "owiIiM85FSqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T-SNE 결과를 시각화 (HOG 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=label, color=color)\n",
        "plt.title('T-SNE Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kpATI3tVFUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UMAP"
      ],
      "metadata": {
        "id": "xtfhskOyifzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "roIOE1wrjC86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NdaOk-5fihMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 정보 가져오기\n",
        "class_labels = [list(classes.keys())[list(classes.values()).index(i)] for i in labels]\n",
        "\n",
        "# 클래스별 색상 매핑\n",
        "class_colors = ['red', 'blue', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink',\n",
        "                'lightblue', 'brown', 'gray', 'olive', 'teal', 'navy', 'salmon', 'gold', 'lightgreen', 'lavender',\n",
        "                'skyblue', 'tan', 'coral', 'orchid', 'darkgreen', 'silver']"
      ],
      "metadata": {
        "id": "bWEfXTfcj2Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 모델 생성 및 학습 ( SIFT로 추출한 feature 사용)\n",
        "umap_model = umap.UMAP(n_components=2, learning_rate=200, random_state=42)\n",
        "umap_result = umap_model.fit_transform(embedded_features)"
      ],
      "metadata": {
        "id": "RBTriDwRJrMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 결과를 시각화 ( SIFT로 추출한 feature 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(umap_result[indices, 0], umap_result[indices, 1], label=label, color=color)\n",
        "plt.title('UMAP Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ref4iSBEJrrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 모델 생성 및 학습 ( HOG로 추출한 feature 사용)\n",
        "umap_model = umap.UMAP(n_components=2, learning_rate=200, random_state=42)\n",
        "umap_result = umap_model.fit_transform(hog_features)"
      ],
      "metadata": {
        "id": "5H6ONC1MijtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP 결과를 시각화 ( HOG로 추출한 feature 사용)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, color in zip(set(class_labels), class_colors):\n",
        "    indices = [i for i, x in enumerate(class_labels) if x == label]\n",
        "    plt.scatter(umap_result[indices, 0], umap_result[indices, 1], label=label, color=color)\n",
        "plt.title('UMAP Visualization')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sd4DWeSTiqyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성"
      ],
      "metadata": {
        "id": "XMOtVX1T8zu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "e0yB7kJWG9oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 준비\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for images, labels, paths in train_loader:\n",
        "    # 이미지 데이터를 1차원 벡터로 변환\n",
        "    images = images.view(images.size(0), -1)\n",
        "    train_images.append(images.numpy())\n",
        "    train_labels.append(labels.numpy())\n",
        "\n",
        "train_images = np.concatenate(train_images, axis=0)\n",
        "train_labels = np.concatenate(train_labels, axis=0)\n",
        "\n",
        "# 테스트 데이터 준비\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for images, labels, paths in test_loader:\n",
        "    # 이미지 데이터를 1차원 벡터로 변환\n",
        "    images = images.view(images.size(0), -1)\n",
        "    test_images.append(images.numpy())\n",
        "    test_labels.append(labels.numpy())\n",
        "\n",
        "test_images = np.concatenate(test_images, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "# Random Forest 모델 생성 및 학습\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(train_images, train_labels)\n",
        "\n",
        "# 예측\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "127llhZJ86o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "xBZt7eFTG_eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model List"
      ],
      "metadata": {
        "id": "JLjcF_rC_l-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-DNN"
      ],
      "metadata": {
        "id": "FQOpdoLX-L6c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sl1HoPos-SAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-CNN basic"
      ],
      "metadata": {
        "id": "p_mc2Pzm-P2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        ############### Conv2d, MaxPool2d, Linear 함수에 들어갈 파라미터를 채우세요 ##############\n",
        "        self.conv1 = nn.Conv2d(3, 10, 3) # in_channel, out_channel, kernel size\n",
        "        self.pool = nn.MaxPool2d(3, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
        "        self.fc1 = nn.Linear(56180, 160) # in_features, out_features\n",
        "        self.fc2 = nn.Linear(160, 120)\n",
        "        self.fc3 = nn.Linear(120, 26)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        ###########################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "B1g9uChC-SSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use GPU if it's available # colab 런타임 유형 변경에서 GPU 선택할 것\n",
        "model = Net().to(device) # define the network"
      ],
      "metadata": {
        "id": "-sznHOjK-Vsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "print(output.size())\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "Ebd7-pex-XvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-ResNet50"
      ],
      "metadata": {
        "id": "DmnCSZA68p1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_model_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_model_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_model_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_model_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_model_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x, h"
      ],
      "metadata": {
        "id": "3GIVUYCI8ZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "QRb75CaC8YpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                               stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ],
      "metadata": {
        "id": "twSUre1m8YYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model_info"
      ],
      "metadata": {
        "id": "7tQhxT6P8viD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "Model_Info = namedtuple('Model_Info', ['block', 'n_blocks', 'channels'])\n",
        "\n",
        "Model_config = Model_Info(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "3SDkZ6Nb8xO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "pretrained_model = models.resnet50(pretrained = True)\n",
        "\n",
        "# Fine Tuning\n",
        "IN_FEATURES = pretrained_model.fc.in_features \n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
        "pretrained_model.fc = fc\n",
        "model = CustomModel(Model_config, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "4emuVAQs8ylG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Load\n",
        "model.load_state_dict(pretrained_model.state_dict())"
      ],
      "metadata": {
        "id": "cseDfD2K8zfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "-25g1f6h80Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR_finder"
      ],
      "metadata": {
        "id": "5WjFwY-a80lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "3BD5cyC182aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "iTxkpY_A83OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "        torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "    def range_test(self, iterator, end_lr = 10, num_iter = 100, \n",
        "                   smooth_f = 0.05, diverge_th = 5):\n",
        "        \n",
        "        lrs = []\n",
        "        losses = []\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        \n",
        "        iterator = IteratorWrapper(iterator)\n",
        "        \n",
        "        for iteration in range(num_iter):\n",
        "\n",
        "            loss = self._train_batch(iterator)\n",
        "\n",
        "            #update lr\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "            if iteration > 0:\n",
        "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "                \n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "\n",
        "            losses.append(loss)\n",
        "            \n",
        "            if loss > diverge_th * best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "                       \n",
        "        #reset model to initial parameters\n",
        "        model.load_state_dict(torch.load('init_params.pt'))\n",
        "                    \n",
        "        return lrs, losses\n",
        "\n",
        "    def _train_batch(self, iterator):\n",
        "        \n",
        "        self.model.train()\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        x, y = iterator.get_batch()\n",
        "        \n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        y_pred, _ = self.model(x)\n",
        "                \n",
        "        loss = self.criterion(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return loss.item()\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "class IteratorWrapper:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self._iterator = iter(iterator)\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            inputs, labels = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            self._iterator = iter(self.iterator)\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_batch(self):\n",
        "        return next(self)"
      ],
      "metadata": {
        "id": "zVpRNNGX848A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 30\n",
        "\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "metadata": {
        "id": "gsyb7oK885n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 30):\n",
        "    \n",
        "    if skip_end == 0:\n",
        "        lrs = lrs[skip_start:]\n",
        "        losses = losses[skip_start:]\n",
        "    else:\n",
        "        lrs = lrs[skip_start:-skip_end]\n",
        "        losses = losses[skip_start:-skip_end]\n",
        "    \n",
        "    fig = plt.figure(figsize = (16,8))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(lrs, losses)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('Learning rate')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid(True, 'both', 'x')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aGmKF75Q878P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOUND_LR = 1e-3\n",
        "\n",
        "params = [\n",
        "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "          {'params': model.fc.parameters()}\n",
        "         ]\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(params, lr = FOUND_LR, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)"
      ],
      "metadata": {
        "id": "2oUFzEwX88sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='./net_pretrained.pth'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: './net_pretrained.pth'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "TQauBjM58957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "LmhpfKR387Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(k, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc_1 = correct_1 / batch_size\n",
        "        acc_k = correct_k / batch_size\n",
        "    return acc_1, acc_k"
      ],
      "metadata": {
        "id": "vt_ASe_q87JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc_1 += acc_1.item()\n",
        "        epoch_acc_5 += acc_5.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "qO-WJvKE9Aqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "           x = x.to(device)\n",
        "           y = y.to(device)\n",
        "\n",
        "           y_pred, _ = model(x)\n",
        "\n",
        "           loss = criterion(y_pred, y)\n",
        "\n",
        "           acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
        "\n",
        "           epoch_loss += loss.item()\n",
        "           epoch_acc_1 += acc_1.item()\n",
        "           epoch_acc_5 += acc_5.item()\n",
        "\n",
        "          \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "yfFjUgwB9Cjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "k6XPUIJz9DSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "result_list = []\n",
        "lr_list = []\n",
        "\n",
        "patience = 5\n",
        "\n",
        "early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "\n",
        "for epoch in range(100):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc_1, train_acc_5 = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_loader, criterion, device)\n",
        "      \n",
        "    early_stopping(valid_loss, model)\n",
        "    lr_list.append(optimizer.param_groups[0][\"lr\"]) \n",
        "\n",
        "    # patience 동안 val_loss가 감소하지 않으면 조기 종료\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "\n",
        "    # val_loss 감소하면 best model 불러오기 \n",
        "    model.load_state_dict(torch.load('./net_pretrained.pth'))\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc_1: {train_acc_1*100:6.2f}% | Train Acc_5: {train_acc_5*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc_1: {valid_acc_1*100:6.2f}% | Train Acc_5: {train_acc_5*100:6.2f}%')\n",
        "\n",
        "    result = {\n",
        "    'EPOCH': epoch,\n",
        "    'Train Loss': train_loss,\n",
        "    'Train acc_1': train_acc_1,\n",
        "    'Train acc_5': train_acc_5,\n",
        "    'Valid Loss': valid_loss,\n",
        "    'Valid acc_1': valid_acc_1,\n",
        "    'Valid acc_5': valid_acc_5}\n",
        "  \n",
        "    result_list.append(result)\n",
        "  \n",
        "result_df = pd.DataFrame(result_list)"
      ],
      "metadata": {
        "id": "5ydfXopX9D3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "18G7yplz89Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss 및 Acc 변화 그래프\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(result_df['EPOCH'], result_df['Train Loss'], label='Train Loss')\n",
        "axes[0].plot(result_df['EPOCH'], result_df['Valid Loss'], label='Valid Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_title('Loss')\n",
        "\n",
        "axes[1].plot(result_df['EPOCH'], result_df['Train acc_1'], label='Train acc_1')\n",
        "axes[1].plot(result_df['EPOCH'], result_df['Valid acc_1'], label='Valid acc_1')\n",
        "axes[1].legend()\n",
        "axes[1].set_title('ACC_1')\n",
        "\n",
        "axes[2].plot(result_df['EPOCH'], result_df['Train acc_5'], label='Train acc_5')\n",
        "axes[2].plot(result_df['EPOCH'], result_df['Valid acc_5'], label='Valid acc_5')\n",
        "axes[2].legend()\n",
        "axes[2].set_title('ACC_5')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IhKgwzon9zG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lr_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Learning Rate\")"
      ],
      "metadata": {
        "id": "5JihiaQO-2Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./net_pretrained.pth'))"
      ],
      "metadata": {
        "id": "cBcW3D2388_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc_1, test_acc_5 = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | Test Acc @5: {test_acc_5*100:6.2f}%')"
      ],
      "metadata": {
        "id": "YgCrh4cL9HUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}